{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jul 31 14:33:57 2023\n",
    "\n",
    "@author: Lin\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "import numpy as np\n",
    "from numpy import seterr\n",
    "seterr(all='raise')\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import multiprocess as mp\n",
    "import sys\n",
    "sys.path.append(current_path+'/../../')\n",
    "import myInput\n",
    "import post_processing\n",
    "import PACKAGE_MP_3DLinear as linear3d\n",
    "\n",
    "import importlib\n",
    "importlib.reload(post_processing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(i, j):\n",
    "    \"\"\"Get the row order of grain i and grain j in MisoEnergy.txt (i < j)\"\"\"\n",
    "    if i < j: return i+(j-1)*(j)/2\n",
    "    else: return j+(i-1)*(i)/2\n",
    "\n",
    "def init2EAarray(init_file_path, grain_num):\n",
    "    euler_angle_array = np.ones((grain_num, 3))*-2\n",
    "    with open(init_file_path, 'r', encoding='utf-8') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i > 2: euler_angle_array[int(line.split()[1])-1] = np.array([float(line.split()[2]), float(line.split()[3]), float(line.split()[4])])\n",
    "    # Check if missing grains\n",
    "    for i in range(grain_num):\n",
    "        if euler_angle_array[i,0] == -2:\n",
    "            print(\"Missing grains here!\")\n",
    "            euler_angle_array[i] = np.array([0,0,0])\n",
    "    return euler_angle_array\n",
    "\n",
    "def output_init_from_dump(dump_file_path, euler_angle_array, init_file_path_output):\n",
    "    # output the init file with euler_angle_array and one dump file\n",
    "    # Read necessary information from dump file\n",
    "    with open(dump_file_path) as file:\n",
    "        box_size = np.zeros(3)\n",
    "        for i, line in enumerate(file):\n",
    "            if i==3: num_sites = int(line)\n",
    "            if i==5: box_size[0] = np.array(line.split(), dtype=float)[-1]\n",
    "            if i==6: box_size[1] = np.array(line.split(), dtype=float)[-1]\n",
    "            if i==7: box_size[2] = np.array(line.split(), dtype=float)[-1]\n",
    "            if i==8: name_vars = line.split()[2:]\n",
    "            if i>8: break\n",
    "    box_size = np.ceil(box_size).astype(int) #reformat box_size\n",
    "    entry_length = num_sites+9 #there are 9 header lines in each entry\n",
    "\n",
    "\n",
    "    # write the IC files and read the dump data\n",
    "    # create IC file\n",
    "    IC_nei = []\n",
    "    IC_nei.append(\"# This line is ignored\\n\")\n",
    "    IC_nei.append(\"Values\\n\")\n",
    "    IC_nei.append(\"\\n\")\n",
    "    with open(init_file_path_output, 'w') as output_file:\n",
    "        output_file.writelines( IC_nei )\n",
    "    IC_nei = []\n",
    "    # read and write\n",
    "    with open(init_file_path_output, 'a') as output_file:\n",
    "        with open(dump_file_path) as file:\n",
    "            for i, line in tqdm(enumerate(file), \"EXTRACTING SPPARKS DUMP (%s.dump)\"%dump_file_path[-20:], total=entry_length):\n",
    "                if i==1: time_step = int(float(line.split()[-1])) #log the time step\n",
    "                atom_num = i-9 #track which atom line we're on\n",
    "                if atom_num>=0 and atom_num<num_sites:\n",
    "                    line_split = np.array(line.split(), dtype=float)\n",
    "                    grain_id = int(line_split[1])-1\n",
    "                    output_file.write(f\"{int(line_split[0])} {int(line_split[1])} {euler_angle_array[grain_id, 0]} {euler_angle_array[grain_id, 1]} {euler_angle_array[grain_id, 2]}\\n\")\n",
    "\n",
    "    return box_size, entry_length\n",
    "\n",
    "def output_init_neighbor_from_init(interval, box_size, init_file_path_input, init_file_path_output):\n",
    "    # Output the init_nighbor5 with init file\n",
    "\n",
    "    nei_num = (2*interval+3)**3-1\n",
    "    size_x,size_y,size_z = box_size\n",
    "    img = np.zeros((size_y,size_x,size_z)) #Figure of all sites with GrainID\n",
    "\n",
    "    print(f\"> img matrix start.\")\n",
    "    for k in tqdm(range(size_z)): # z-axis\n",
    "        for i in range(size_y): # y-axis\n",
    "            for j in range(size_x): # x-axis\n",
    "                img[i,j,k] = int(k*size_x*size_y + i*size_x + j)\n",
    "    print(f\"> img matrix end\")\n",
    "\n",
    "    IC_nei = []\n",
    "    IC_nei.append(\"# This line is ignored\\n\")\n",
    "    IC_nei.append(\"3 dimension\\n\")\n",
    "    IC_nei.append(f\"{nei_num} max neighbors\\n\")\n",
    "    IC_nei.append(f\"{size_x*size_y*size_z} sites\\n\")\n",
    "    IC_nei.append(f\"0 {size_x} xlo xhi\\n\")\n",
    "    IC_nei.append(f\"0 {size_y} ylo yhi\\n\")\n",
    "    IC_nei.append(f\"0 {size_z} zlo zhi\\n\")\n",
    "    IC_nei.append(\"\\n\")\n",
    "    IC_nei.append(\"Sites\\n\")\n",
    "    IC_nei.append(\"\\n\")\n",
    "    with open(init_file_path_output, 'w') as file:\n",
    "        file.writelines( IC_nei )\n",
    "    IC_nei = []\n",
    "\n",
    "    print(\"> Sites start writing\")\n",
    "    with open(init_file_path_output, 'a') as file:\n",
    "        for k in tqdm(range(size_z)): # z-axis\n",
    "            for i in range(size_y): # y-axis\n",
    "                for j in range(size_x): # x-axis\n",
    "                    file.write(f\"{int(img[i,j,k] + 1)} {float(j)} {float(i)} {float(k)}\\n\")\n",
    "    print(\"> Sites end writing\")\n",
    "\n",
    "    IC_nei.append(\"\\n\")\n",
    "    IC_nei.append(\"Neighbors\\n\")\n",
    "    IC_nei.append(\"\\n\")\n",
    "    with open(init_file_path_output, 'a') as file:\n",
    "        file.writelines( IC_nei )\n",
    "    IC_nei = []\n",
    "\n",
    "    # offset value setting before neighboring start\n",
    "    offsets = np.array(np.meshgrid(\n",
    "    np.arange(-(interval + 1), interval + 2),\n",
    "    np.arange(-(interval + 1), interval + 2),\n",
    "    np.arange(-(interval + 1), interval + 2),\n",
    "    )).T.reshape(-1, 3)\n",
    "    # Filter out the [0, 0, 0] offset since we want to skip it\n",
    "    offsets = offsets[np.any(offsets != 0, axis=1)]\n",
    "\n",
    "    def process_chunk(start_k, end_k, file_name):\n",
    "        max_length_neighbors = 0\n",
    "        with open(file_name, 'w') as file:\n",
    "            for k in tqdm(range(start_k, end_k)): # z-axis\n",
    "                for i in range(size_y): # y-axis\n",
    "                    for j in range(size_x): # x-axis\n",
    "                        tmp_nei = f\"{int(img[i,j,k] + 1)} \"\n",
    "                        # Compute the indices with wrapping around boundaries (using np.mod)\n",
    "                        indices = (np.array([i, j, k]) + offsets) % np.array([size_y, size_x, size_z])\n",
    "                        # Extract the values from 'img' using advanced indexing\n",
    "                        neighbour_values = img[indices[:, 0], indices[:, 1], indices[:, 2]].astype('int')\n",
    "                        # Convert values to 1-based indexing and concatenate into a string\n",
    "                        tmp_nei += ' '.join(map(str, neighbour_values + 1))\n",
    "                        max_length_neighbors = max(max_length_neighbors, len(tmp_nei))\n",
    "                        file.write(tmp_nei + \"\\n\")\n",
    "            file.write(\"\\n\")\n",
    "        print(f\"The max length of neighbor data line is {max_length_neighbors}\")\n",
    "\n",
    "    print(\"> Neighbors start writing\")\n",
    "    # ecessary init for multi cores writing\n",
    "    num_processes = mp.cpu_count() # or choose a number that suits your machine\n",
    "    chunk_size = size_z // num_processes\n",
    "    processes = []\n",
    "    temp_files = []\n",
    "    # Assign tasks for processors\n",
    "    for p in range(num_processes):\n",
    "        start_k = p * chunk_size\n",
    "        end_k = (p + 1) * chunk_size if p != num_processes - 1 else size_z\n",
    "        temp_file = f'{init_file_path_output}_temp_{p}.txt'\n",
    "        temp_files.append(temp_file)\n",
    "        process = mp.Process(target=process_chunk, args=(start_k, end_k, temp_file))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "    # Wait for all processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    # Concatenate all temporary files\n",
    "    with open(init_file_path_output, 'a') as outfile:\n",
    "        for fname in tqdm(temp_files, \"Concatenating \"):\n",
    "            with open(fname) as infile:\n",
    "                outfile.write(infile.read())\n",
    "            os.remove(fname)  # Optional: remove temp file after concatenation\n",
    "\n",
    "    print(\"> Neighbors end writing\")\n",
    "\n",
    "    print(\"> Values start writing\")\n",
    "    with open(init_file_path_input, 'r') as f_read:\n",
    "        tmp_values = f_read.readlines()\n",
    "    print(\"> Values read done\")\n",
    "    with open(init_file_path_output, 'a') as file:\n",
    "        file.writelines(tmp_values[1:])\n",
    "    print(\"> Values end writing\")\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    # File name\n",
    "    # dump file of last time step\n",
    "    last_step = 5\n",
    "    # dump_file_foler = \"/blue/michael.tonks/lin.yang/SPPARKS-VirtualIncEnergy/3d_poly/\"\n",
    "    dump_file_foler = \"/Users/lin/projects/SPPARKS-AGG/examples/Test_SimplifyIncE/2d_triple/\"\n",
    "    # dump_file_name = f\"p_ori_fully5d_aveE_f1.0_t1.0_150_1k_multiCore64_J1_refer_1_0_0_seed56689_kt1.95\"\n",
    "    init_file_folder = dump_file_foler + \"IC/\"\n",
    "    init_file_name = f\"Tri_IC.init\"\n",
    "    init_file_name_final = f\"Tri_IC_neighbors5.init\"\n",
    "    # init_file_name_final = f\"poly_IC150_1k.{last_step}_neighbor5.init\"\n",
    "\n",
    "    # Read init file\n",
    "    grain_num = 3\n",
    "    # euler_angle_array = post_processing.init2EAarray(init_file_folder+init_file_name_original, grain_num)\n",
    "\n",
    "\n",
    "    # Read necessary information from dump file\n",
    "    # dump_file_name_0 = dump_file_foler+dump_file_name+f\".dump.{int(last_step)}\"\n",
    "    # box_size, entry_length = post_processing.output_init_from_dump(dump_file_name_0, euler_angle_array, init_file_folder+init_file_name)\n",
    "    # size_x,size_y,size_z = box_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> img matrix start.\n",
      "> img matrix end\n",
      "> Sites start writing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Sites end writing\n",
      "> Neighbors start writing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 46/46 [00:02<00:00, 15.67it/s]\n",
      "100%|██████████| 46/46 [00:02<00:00, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:02<00:00, 15.94it/s]\n",
      "100%|██████████| 46/46 [00:02<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 45/47 [00:02<00:00, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:03<00:00, 15.46it/s]\n",
      " 98%|█████████▊| 46/47 [00:02<00:00, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:02<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:03<00:00, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 46/47 [00:03<00:00, 17.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:02<00:00, 15.96it/s]\n",
      "100%|██████████| 46/46 [00:03<00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The max length of neighbor data line is 1182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:03<00:00, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:02<00:00, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:02<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:03<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of neighbor data line is 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating : 100%|██████████| 11/11 [00:00<00:00, 50.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Neighbors end writing\n",
      "> Values start writing\n",
      "> Values read done\n",
      "> Values end writing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # necessary data for neighbor init file\n",
    "  interval = 5\n",
    "  box_size = np.array([512,512,1])\n",
    "  output_neighbr_init = post_processing.output_init_neighbor_from_init_mp(interval, box_size, init_file_folder+init_file_name, init_file_folder+init_file_name_final)\n",
    "  # output_neighbr_init = output_init_neighbor_from_init(interval, box_size, init_file_folder+init_file_name, init_file_folder+init_file_name_final+\"_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
