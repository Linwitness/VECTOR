{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df856ce3-6a3c-4143-8cac-bce453cc769f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "import numpy as np\n",
    "from numpy import seterr\n",
    "seterr(all='raise')\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(current_path)\n",
    "sys.path.append(current_path+'/../../')\n",
    "import myInput\n",
    "import PACKAGE_MP_Linear as linear2d\n",
    "import post_processing as inclination_processing\n",
    "sys.path.append(current_path+'/../calculate_tangent/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6530ce-3418-45ab-a3b9-b4973593b323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def simple_magnitude(freqArray):\n",
    "    xLim = [0, 360]\n",
    "    binValue = 10.01\n",
    "    binNum = round((abs(xLim[0])+abs(xLim[1]))/binValue)\n",
    "    xCor = np.linspace((xLim[0]+binValue/2),(xLim[1]-binValue/2),binNum)\n",
    "\n",
    "    freqArray_circle = np.ones(binNum)\n",
    "    freqArray_circle = freqArray_circle/sum(freqArray_circle*binValue)\n",
    "\n",
    "    magnitude_max = np.max(abs(freqArray - freqArray_circle))/np.average(freqArray_circle)\n",
    "    magnitude_ave = np.average(abs(freqArray - freqArray_circle))/np.average(freqArray_circle)\n",
    "\n",
    "    magnitude_stan = np.sqrt(np.sum((abs(freqArray - freqArray_circle)/np.average(freqArray_circle) - magnitude_ave)**2)/binNum)\n",
    "\n",
    "    return magnitude_ave, magnitude_stan\n",
    "\n",
    "    # coeff_high = abs(np.cos((xCor-90)/180*np.pi))\n",
    "    # coeff_low = abs(np.cos((xCor)/180*np.pi))\n",
    "    # return np.sum(freqArray * coeff_high)/np.sum(freqArray * coeff_low)\n",
    "\n",
    "def find_fittingEllipse2(array): #failure\n",
    "    K_mat = []\n",
    "    Y_mat = []\n",
    "\n",
    "    # Get the self-variable\n",
    "    X = array[:,0]\n",
    "    Y = array[:,1]\n",
    "\n",
    "    K_mat = np.hstack([X**2, X*Y, Y**2, X, Y])\n",
    "    Y_mat = np.ones_like(X)\n",
    "\n",
    "    X_mat = np.linalg.lstsq(K_mat, Y_mat)[0].squeeze()\n",
    "    # X_mat = (K_mat.T*K_mat).I * K_mat.T * Y_mat\n",
    "\n",
    "    print('The ellipse is given by {0:.3}x^2 + {1:.3}xy+{2:.3}y^2+{3:.3}x+{4:.3}y = 1'.format(X_mat[0], X_mat[1], X_mat[2], X_mat[3], X_mat[4]))\n",
    "    print(X_mat)\n",
    "\n",
    "    return X_mat\n",
    "\n",
    "def get_poly_center(micro_matrix, step):\n",
    "    # Get the center of all non-periodic grains in matrix\n",
    "    num_grains = int(np.max(micro_matrix[step,:]))\n",
    "    center_list = np.zeros((num_grains,2))\n",
    "    sites_num_list = np.zeros(num_grains)\n",
    "    ave_radius_list = np.zeros(num_grains)\n",
    "    coord_refer_i = np.zeros((micro_matrix.shape[1], micro_matrix.shape[2]))\n",
    "    coord_refer_j = np.zeros((micro_matrix.shape[1], micro_matrix.shape[2]))\n",
    "    for i in range(micro_matrix.shape[1]):\n",
    "        for j in range(micro_matrix.shape[2]):\n",
    "            coord_refer_i[i,j] = i\n",
    "            coord_refer_j[i,j] = j\n",
    "\n",
    "    table = micro_matrix[step,:,:,0]\n",
    "    for i in range(num_grains):\n",
    "        sites_num_list[i] = np.sum(table == i+1)\n",
    "\n",
    "        if (sites_num_list[i] < 500) or \\\n",
    "           (np.max(coord_refer_i[table == i+1]) - np.min(coord_refer_i[table == i+1]) == micro_matrix.shape[1]) or \\\n",
    "           (np.max(coord_refer_j[table == i+1]) - np.min(coord_refer_j[table == i+1]) == micro_matrix.shape[2]): # grains on bc are ignored\n",
    "          center_list[i, 0] = 0\n",
    "          center_list[i, 1] = 0\n",
    "          sites_num_list[i] == 0\n",
    "        else:\n",
    "          center_list[i, 0] = np.sum(coord_refer_i[table == i+1]) / sites_num_list[i]\n",
    "          center_list[i, 1] = np.sum(coord_refer_j[table == i+1]) / sites_num_list[i]\n",
    "    ave_radius_list = np.sqrt(sites_num_list / np.pi)\n",
    "\n",
    "    return center_list, ave_radius_list\n",
    "\n",
    "def get_poly_statistical_radius(micro_matrix, sites_list, step):\n",
    "    # Get the max offset of average radius and real radius\n",
    "    center_list, ave_radius_list = get_poly_center(micro_matrix, step)\n",
    "    num_grains = int(np.max(micro_matrix[step,:]))\n",
    "\n",
    "    max_radius_offset_list = np.zeros(num_grains)\n",
    "    for n in range(num_grains):\n",
    "        center = center_list[n]\n",
    "        ave_radius = ave_radius_list[n]\n",
    "        sites = sites_list[n]\n",
    "\n",
    "        if ave_radius != 0:\n",
    "          for sitei in sites:\n",
    "              [i,j] = sitei\n",
    "              current_radius = np.sqrt((i - center[0])**2 + (j - center[1])**2)\n",
    "              radius_offset = abs(current_radius - ave_radius)\n",
    "              if radius_offset > max_radius_offset_list[n]: max_radius_offset_list[n] = radius_offset\n",
    "\n",
    "          max_radius_offset_list[n] = max_radius_offset_list[n] / ave_radius\n",
    "\n",
    "    max_radius_offset = np.average(max_radius_offset_list[max_radius_offset_list!=0])\n",
    "    area_list = np.pi*ave_radius_list*ave_radius_list\n",
    "    if np.sum(area_list) == 0: max_radius_offset = 0\n",
    "    else: max_radius_offset = np.sum(max_radius_offset_list * area_list) / np.sum(area_list)\n",
    "\n",
    "    return max_radius_offset\n",
    "\n",
    "def get_poly_statistical_ar(micro_matrix, step):\n",
    "    # Get the average aspect ratio\n",
    "    num_grains = int(np.max(micro_matrix[step,:]))\n",
    "    sites_num_list = np.zeros(num_grains)\n",
    "    coord_refer_i = np.zeros((micro_matrix.shape[1], micro_matrix.shape[2]))\n",
    "    coord_refer_j = np.zeros((micro_matrix.shape[1], micro_matrix.shape[2]))\n",
    "    for i in range(micro_matrix.shape[1]):\n",
    "        for j in range(micro_matrix.shape[2]):\n",
    "            coord_refer_i[i,j] = i\n",
    "            coord_refer_j[i,j] = j\n",
    "\n",
    "    aspect_ratio_i = np.zeros((num_grains,2))\n",
    "    aspect_ratio_j = np.zeros((num_grains,2))\n",
    "    aspect_ratio = np.zeros(num_grains)\n",
    "    table = micro_matrix[step,:,:,0]\n",
    "\n",
    "    aspect_ratio_i_list = [[] for _ in range(int(num_grains))]\n",
    "    aspect_ratio_j_list = [[] for _ in range(int(num_grains))]\n",
    "    for i in range(micro_matrix.shape[1]):\n",
    "        for j in range(micro_matrix.shape[2]):\n",
    "            grain_id = int(table[i][j]-1)\n",
    "            sites_num_list[grain_id] +=1\n",
    "            aspect_ratio_i_list[grain_id].append(coord_refer_i[i][j])\n",
    "            aspect_ratio_j_list[grain_id].append(coord_refer_j[i][j])\n",
    "\n",
    "    for i in range(num_grains):\n",
    "        aspect_ratio_i[i, 0] = len(list(set(aspect_ratio_i_list[i])))\n",
    "        aspect_ratio_j[i, 1] = len(list(set(aspect_ratio_j_list[i])))\n",
    "        if aspect_ratio_j[i, 1] == 0: aspect_ratio[i] = 0\n",
    "        else: aspect_ratio[i] = aspect_ratio_i[i, 0] / aspect_ratio_j[i, 1]\n",
    "\n",
    "    # aspect_ratio = np.average(aspect_ratio[aspect_ratio!=0])\n",
    "    aspect_ratio = np.sum(aspect_ratio * sites_num_list) / np.sum(sites_num_list)\n",
    "\n",
    "    return aspect_ratio\n",
    "\n",
    "def get_normal_vector(grain_structure_figure_one, grain_num):\n",
    "    nx = grain_structure_figure_one.shape[0]\n",
    "    ny = grain_structure_figure_one.shape[1]\n",
    "    ng = np.max(grain_structure_figure_one)\n",
    "    cores = 32\n",
    "    loop_times = 5\n",
    "    P0 = grain_structure_figure_one\n",
    "    R = np.zeros((nx,ny,2))\n",
    "    smooth_class = linear2d.linear_class(nx,ny,ng,cores,loop_times,P0,R)\n",
    "\n",
    "    smooth_class.linear_main(\"inclination\")\n",
    "    P = smooth_class.get_P()\n",
    "    # sites = smooth_class.get_gb_list(1)\n",
    "    # print(len(sites))\n",
    "    # for id in range(2,grain_num+1): sites += smooth_class.get_gb_list(id)\n",
    "    # print(len(sites))\n",
    "    sites = smooth_class.get_all_gb_list()\n",
    "    sites_together = []\n",
    "    for id in range(len(sites)): sites_together += sites[id]\n",
    "    print(\"Total num of GB sites: \" + str(len(sites_together)))\n",
    "\n",
    "    return P, sites_together, sites\n",
    "\n",
    "def get_normal_vector_energy_slope(P, sites, sigma, para_name):\n",
    "    xLim = [0, int((1+sigma)/(1-sigma)+1)]\n",
    "    binValue = 1.01\n",
    "    binNum = round((abs(xLim[0])+abs(xLim[1]))/binValue)\n",
    "    xCor = np.linspace((xLim[0]+binValue/2),(xLim[1]-binValue/2),binNum)\n",
    "\n",
    "    freqArray = np.zeros(binNum)\n",
    "    degree_energy = []\n",
    "    for sitei in sites:\n",
    "        [i,j] = sitei\n",
    "        dx,dy = myInput.get_grad(P,i,j)\n",
    "        degree = math.atan2(-dy, dx) + math.pi\n",
    "\n",
    "        degree_energy.append((1+sigma*np.cos(2*degree))/(1-sigma))\n",
    "    for i in range(len(degree_energy)):\n",
    "        freqArray[int((degree_energy[i]-xLim[0])/binValue)] += 1\n",
    "    freqArray = freqArray/sum(freqArray*binValue) # Normalized\n",
    "    plt.plot(xCor, freqArray, linewidth=2, label=para_name)\n",
    "\n",
    "    return freqArray\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40f896-f148-47db-b4eb-be8380a3e0a8",
   "metadata": {},
   "source": [
    "## Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c0a96-372e-4aa7-9e5a-6418b5060b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # File name\n",
    "    npy_file_folder_iso = \"/blue/michael.tonks/lin.yang/SPPARKS-VirtualIncEnergy/2d_poly_multiCoreCompare/results/\"\n",
    "    npy_file_folder = \"/blue/michael.tonks/lin.yang/SPPARKS-VirtualIncEnergy/2d_poly_wellEnergy/results/\"\n",
    "    TJ_energy_type_090 = \"0.9\"\n",
    "\n",
    "    energy_function = \"CosMax1\"\n",
    "    npy_file_name_iso = \"p_ori_ave_aveE_20000_multiCore32_delta0.0_m2_J1_refer_1_0_0_seed56689_kt066.npy\"\n",
    "    npy_file_name_aniso_090 = f\"pz_aveE_20000_{energy_function}_delta{TJ_energy_type_090}_J1_refer_1_0_0_seed56689_kt0.66.npy\"\n",
    "\n",
    "\n",
    "    # Initial data\n",
    "    npy_file_iso = np.load(npy_file_folder_iso + npy_file_name_iso)\n",
    "    npy_file_aniso_090 = np.load(npy_file_folder + npy_file_name_aniso_090)\n",
    "    print(f\"The 0.90 data size is: {npy_file_aniso_090.shape}\")\n",
    "    print(f\"The iso data size is: {npy_file_iso.shape}\")\n",
    "    print(\"READING DATA DONE\")\n",
    "\n",
    "    # Initial container\n",
    "    initial_grain_num = 20000\n",
    "    step_num = npy_file_aniso_090.shape[0]\n",
    "    grain_num_aniso_090 = np.zeros(step_num)\n",
    "    grain_num_iso = np.zeros(step_num)\n",
    "\n",
    "    # Calculate the number of grains\n",
    "    for i in range(step_num):\n",
    "        grain_num_aniso_090[i] = len(set(npy_file_aniso_090[i,:].flatten()))\n",
    "        grain_num_iso[i] = len(set(npy_file_iso[i,:].flatten()))\n",
    "\n",
    "    expected_grain_num = 500\n",
    "    special_step_distribution_090 = int(np.argmin(abs(grain_num_aniso_090 - expected_grain_num)))\n",
    "    special_step_distribution_iso = int(np.argmin(abs(grain_num_iso - expected_grain_num)))\n",
    "    print(\"Found time steps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54191e62-01f3-466a-b5eb-a2ad45e6b952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    label_list = [\"0.0\", \"0.9\"]\n",
    "    sigma_list = np.array(label_list).astype(float)\n",
    "    aniso_mag = np.zeros(len(label_list))\n",
    "    aniso_mag_stand = np.zeros(len(label_list))\n",
    "    aniso_rs = np.zeros(len(label_list))\n",
    "\n",
    "    plt.close()\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "    # Iso\n",
    "    newplace = np.rot90(npy_file_iso[special_step_distribution_iso,:,:,:], 1, (0,1))\n",
    "    P, sites,_ = inclination_processing.get_normal_vector(newplace, initial_grain_num)\n",
    "\n",
    "    slope_list = get_normal_vector_energy_slope(P, sites, sigma_list[0], label_list[0])\n",
    "    aniso_rs[0] = get_poly_statistical_ar(npy_file_iso, special_step_distribution_iso)\n",
    "    print(\"iso done\")\n",
    "\n",
    "    # Aniso - 090\n",
    "    newplace = np.rot90(npy_file_aniso_090[special_step_distribution_090,:,:,:], 1, (0,1))\n",
    "    P, sites,_ = inclination_processing.get_normal_vector(newplace, initial_grain_num)\n",
    "\n",
    "    slope_list = get_normal_vector_energy_slope(P, sites, sigma_list[1], label_list[1])\n",
    "    aniso_rs[1] = get_poly_statistical_ar(npy_file_aniso_090, special_step_distribution_090)\n",
    "    print(f\"{label_list[1]} done\")\n",
    "\n",
    "\n",
    "    # plt.plot(np.linspace(0,len(label_list)-1,len(label_list)), 1/aniso_rs, '.-', markersize=8 linewidth=2)\n",
    "    plt.xlabel(\"Energy\", fontsize=16)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.ylim([-0.05,0.5])\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.savefig(current_path + f\"/figures/anisotropic_poly_20k_pz_frequency_energy_{energy_function}.png\", dpi=400,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c60b67-c7b5-4f03-ba96-435582b5926c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23b4b9-fde2-4c11-b38d-ca329ee8fc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9593f5d-1a19-4651-9399-b0c071662371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UFRC Python-3.8",
   "language": "python",
   "name": "python3-3.8-ufrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
